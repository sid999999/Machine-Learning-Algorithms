{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LogisticRegression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNXKz8VmqADjt8/LrHoOUeE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rikVRkgcw822"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","source":["# **Create the logistic regression class**"],"metadata":{"id":"YQZVWe8syJif"}},{"cell_type":"code","source":["class LogisticRegression1:\n","\n","  def __init__(self, lr=0.001,n_iters=1000):\n","    self.lr=lr\n","    self.n_iters=n_iters\n","    self.weights=None\n","    self.bias=None\n","\n","  def fit(self, X, y):\n","    #init the parameters:\n","    n_samples,n_features = X.shape\n","    self.weights = np.zeros(n_features)\n","    self.bias = 0\n","\n","    #gradient descent\n","    for _ in range(self.n_iters):\n","      linear_model = np.dot(X, self.weights) + self.bias\n","      y_pred = self._sigmoid(linear_model)\n","\n","      #Partial derivatives\n","      dw = (1/n_samples) * np.dot(X.T, y_pred-y) \n","      db = (1/n_samples) * np.sum(y_pred-y) \n","\n","      self.weights -= self.lr*dw\n","      self.bias -= self.lr*db\n","\n","  def predict(self, X):\n","    linear_model = np.dot(X, self.weights) + self.bias\n","    y_pred = self._sigmoid(linear_model)\n","    y_pred_cls = [1 if i>0.5 else 0 for i in y_pred]\n","    return y_pred_cls\n","\n","  #helper method for the sigmoid function\n","  def _sigmoid(self, x):\n","    return 1/(1+ np.exp(-x))"],"metadata":{"id":"fhD6MiJpxQym"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ***Set up the test***"],"metadata":{"id":"_3yQJMQS1Y_3"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn import datasets\n","import matplotlib.pyplot as plt"],"metadata":{"id":"CHxKMZvL1b5W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bc = datasets.load_breast_cancer()\n","X, y = bc.data, bc.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=123)"],"metadata":{"id":"6DFgD1sG1hWr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy(y_true, y_pred):\n","  accuracy = np.sum(y_true == y_pred) / len(y_true)\n","  return accuracy"],"metadata":{"id":"7G2-oWQe1xrL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ***Test the Model***"],"metadata":{"id":"zI6dhzpG1-1g"}},{"cell_type":"code","source":["regressor = LogisticRegression1(lr=0.0001, n_iters=1000)"],"metadata":{"id":"cSoIxong2B24"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["regressor.fit(X_train,y_train)"],"metadata":{"id":"Cm5L-hps2U7Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = regressor.predict(X_test)"],"metadata":{"id":"h1NWdctb2hvM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy(y_test,predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vhFx1T-b2kH6","executionInfo":{"status":"ok","timestamp":1655137083373,"user_tz":240,"elapsed":137,"user":{"displayName":"Sida Wan","userId":"03273855283744897039"}},"outputId":"3781254d-2980-4476-f158-24dabb12f107"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9473684210526315"]},"metadata":{},"execution_count":22}]}]}